<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Random Cut Forest (RCF) Algorithm</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<p>
Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.<br>SPDX-License-Identifier: CC-BY-SA-4.0
</p>
<header id="title-block-header">
<h1 class="title">Random Cut Forest (RCF) Algorithm<a name="randomcutforest"></a></h1>
</header>
<p>Amazon SageMaker Random Cut Forest (RCF) is an unsupervised algorithm for detecting anomalous data points within a data set. These are observations which diverge from otherwise well-structured or patterned data. Anomalies can manifest as unexpected spikes in time series data, breaks in periodicity, or unclassifiable data points. They are easy to describe in that, when viewed in a plot, they are often easily distinguishable from the “regular” data. Including these anomalies in a data set can drastically increase the complexity of a machine learning task since the “regular” data can often be described with a simple model.</p>
<p>With each data point, RCF associates an anomaly score. Low score values indicate that the data point is considered “normal.” High values indicate the presence of an anomaly in the data. The definitions of “low” and “high” depend on the application but common practice suggests that scores beyond three standard deviations from the mean score are considered anomalous.</p>
<p>While there are many applications of anomaly detection algorithms to one-dimensional time series data such as traffic volume analysis or sound volume spike detection, RCF is designed to work with arbitrary-dimensional input. Amazon SageMaker RCF scales well with respect to number of features, data set size, and number of instances.</p>
<p><strong>Topics</strong> + <a href="#rcf-input_output">Input/Output Interface for the RCF Algorithm</a> + <a href="#rcf-instance-recommend">Instance Recommendations for the RCF Algorithm</a> + <a href="#rcf-sample-notebooks">RCF Sample Notebooks</a> + <a href="rcf_how-it-works.md">How RCF Works</a> + <a href="rcf_hyperparameters.md">RCF Hyperparameters</a> + <a href="random-cut-forest-tuning.md">Tune an RCF Model</a> + <a href="rcf-in-formats.md">RCF Response Formats</a></p>
<p>Amazon SageMaker Random Cut Forest supports the <code>train</code> and <code>test</code> data channels. The optional test channel is used to compute accuracy, precision, recall, and F1-score metrics on labeled data. Train and test data content types can be either <code>application/x-recordio-protobuf</code> or <code>text/csv</code> formats. For the test data, when using text/csv format, the content must be specified as text/csv;label_size=1 where the first column of each row represents the anomaly label: “1” for an anomalous data point and “0” for a normal data point. You can use either File mode or Pipe mode to train RCF models on data that is formatted as <code>recordIO-wrapped-protobuf</code> or as <code>CSV</code></p>
<p>Also note that the train channel only supports <code>S3DataDistributionType=ShardedByS3Key</code> and the test channel only supports <code>S3DataDistributionType=FullyReplicated</code>. The S3 distribution type can be specified using the Python SDK as follows:</p>
<pre><code>  import sagemaker
    
  # specify Random Cut Forest training job information and hyperparameters
  rcf = sagemaker.estimator.Estimator(...)
    
  # explicitly specify &quot;SharededByS3Key&quot; distribution type
  train_data = sagemaker.s3_input(
       s3_data=s3_training_data_location,
       content_type=&#39;text/csv;label_size=0&#39;,
       distribution=&#39;ShardedByS3Key&#39;)
    
  # run the training job on input data stored in S3
  rcf.fit({&#39;train&#39;: train_data})</code></pre>
<p>See the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/API_S3DataSource.html">Amazon SageMaker Data Types documentation</a> for more information on customizing the S3 data source attributes. Finally, in order to take advantage of multi-instance training the training data must be partitioned into at least as many files as instances.</p>
<p>For inference, RCF supports <code>application/x-recordio-protobuf</code>, <code>text/csv</code> and <code>application/json</code> input data content types. See the <a href="sagemaker-algo-common-data-formats.md">Common Data Formats for Built-in Algorithms</a> documentation for more information. RCF inference returns <code>application/x-recordio-protobuf</code> or <code>application/json</code> formatted output. Each record in these output data contains the corresponding anomaly scores for each input data point. See <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html">Common Data Formats--Inference</a> for more information.</p>
<p>For more information on input and output file formats, see <a href="rcf-in-formats.md">RCF Response Formats</a> for inference and the <a href="#rcf-sample-notebooks">RCF Sample Notebooks</a>.</p>
<p>For training, we recommend the <code>ml.m4</code>, <code>ml.c4</code>, and <code>ml.c5</code> instance families. For inference we recommend using a <code>ml.c5.xl</code> instance type in particular, for maximum performance as well as minimized cost per hour of usage. Although the algorithm could technically run on GPU instance types it does not take advantage of GPU hardware.</p>
<p>For an example of how to train an RCF model and perform inferences with it, see the <a href="https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/random_cut_forest/random_cut_forest.ipynb">Introduction to SageMaker Random Cut Forests</a> notebook. For a sample notebook that uses the Amazon SageMaker Random Cut Forest algorithm for anomaly detection, see <a href="https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/random_cut_forest/random_cut_forest.ipynb">An Introduction to SageMaker Random Cut Forests</a>. For instructions how to create and access Jupyter notebook instances that you can use to run the example in Amazon SageMaker, see <a href="nbi.md">Use Notebook Instances</a>. Once you have created a notebook instance and opened it, select the <strong>SageMaker Examples</strong> tab to see a list of all the Amazon SageMaker samples. To open a notebook, click on its <strong>Use</strong> tab and select <strong>Create copy</strong>.</p>
</body>
</html>
